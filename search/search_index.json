{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ML Notes","text":"<p>Welcome to my machine learning notes for personal reference and sharing.</p>"},{"location":"#quick-start","title":"Quick start","text":"<ul> <li>Install and serve locally:</li> </ul> <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\nmkdocs serve\n</code></pre> <ul> <li>To publish: create the GitHub repo <code>pushkarnagar.github.io</code> and push (commands in README).</li> </ul>"},{"location":"#structure-suggestions","title":"Structure suggestions","text":"<ul> <li>Organize by topic folders under <code>docs/</code> (e.g., <code>00-basics</code>, <code>01-deep-learning</code>).</li> <li>Add notebooks converted to Markdown in <code>docs/notes/</code> or use <code>mkdocs-jupyter</code> plugin to render them directly.</li> </ul>"},{"location":"00-basics/linear_regression/","title":"Linear Regression","text":"<p>Concise study notes on ordinary least squares linear regression.</p>"},{"location":"00-basics/linear_regression/#at-a-glance","title":"At a glance","text":"<ul> <li>Model: linear mapping from features to target.</li> <li>Use closed-form solution for small datasets; use gradient methods or regularized solvers otherwise.</li> </ul>"},{"location":"00-basics/linear_regression/#model","title":"Model","text":"<p>Predict with weights $w$ and bias $b$:</p> <p>$y = w^{\\top} x + b$</p> <p>The normal-equation (closed-form) solution is</p> <p>$$ w = (X^{\\top} X)^{-1} X^{\\top} y $$</p> <p>where $X$ is the n\u00d7d design matrix (rows = examples).</p>"},{"location":"00-basics/linear_regression/#loss","title":"Loss","text":"<ul> <li>Mean squared error (MSE):</li> </ul> <p>$$ \\mathrm{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$</p>"},{"location":"00-basics/linear_regression/#practical-tips","title":"Practical tips","text":"<ul> <li>Regularization: Ridge adds $\\lambda |w|_2^2$, Lasso adds $\\lambda |w|_1$.</li> <li>Center and scale features for gradient-based solvers.</li> <li>Check condition number of $X^{\\top}X$; if ill-conditioned prefer regularization or SVD.</li> </ul>"},{"location":"00-basics/linear_regression/#minimal-python-example","title":"Minimal Python example","text":"<pre><code>import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nX = np.array([[1], [2], [3], [4]])\ny = np.array([3, 5, 7, 9])  # approx y = 2x + 1\n\nmodel = LinearRegression().fit(X, y)\nprint('coef=', model.coef_, 'intercept=', model.intercept_)\n</code></pre>"},{"location":"00-basics/linear_regression/#references","title":"References","text":"<ul> <li>Ordinary Least Squares, linear algebra textbooks.</li> <li>scikit-learn <code>LinearRegression</code> and <code>Ridge</code>, <code>Lasso</code> implementations.</li> </ul>"}]}